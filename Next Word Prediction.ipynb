{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = open('corpus.txt','r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_newLine(text):\n",
    "    return text.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_punc(text):\n",
    "    puncs = '!\"#$%&()*+,./:;<=>?@[\\\\]^_`{|}~'\n",
    "    return ''.join([w.strip(puncs) for w in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = remove_newLine(text)\n",
    "    sentences = sent_tokenize(text)\n",
    "    text = ''.join([split_punc(sent) for sent in sentences])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams(text):\n",
    "    return nltk.collocations.BigramCollocationFinder.from_words(text.split())\n",
    "    #for trigram, freq in trigrams.ngram_fd.items():\n",
    "    #    print (trigram, freq)\n",
    "def trigrams(text):\n",
    "    return nltk.collocations.TrigramCollocationFinder.from_words(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = preprocess(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BigramCounts = bigrams(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "سيكون كل شيء على ما يرام بعد أن\n"
     ]
    }
   ],
   "source": [
    "inputxt = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputxt preprocess\n",
    "inputext = preprocess(inputxt)\n",
    "#divide to bigrams\n",
    "inputext = [bi for bi, freq in bigrams(inputext).ngram_fd.items()]\n",
    "#get last pair which is important to predict\n",
    "inputext = inputext[-1]\n",
    "#concatenate pair's string\n",
    "inputext = ' '.join(inputext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputextptrn = '^'+inputext.split()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates =  []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bigram, freq in BigramCounts.ngram_fd.items():\n",
    "    if re.match(inputextptrn,' '.join(bigram)) != None:\n",
    "        candidates.append((' '.join(bigram),freq))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Candidateset = set(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedCandidates = sorted(Candidateset,key=lambda x: x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('أن يكون', 20),\n",
       " ('أن تكون', 17),\n",
       " ('أن هذا', 16),\n",
       " ('أن هذه', 15),\n",
       " ('أنه كان', 14),\n",
       " ('أن هناك', 13),\n",
       " ('أن تعرف', 10),\n",
       " ('أن كل', 10),\n",
       " ('أن ترى', 9),\n",
       " ('أنه لم', 8)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedCandidates[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumOfAllRepeations = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for can in sortedCandidates:\n",
    "    sumOfAllRepeations += can[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1622"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumOfAllRepeations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TopN = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for can in sortedCandidates[:10]:\n",
    "    TopN.append((can[0] , str((can[1]+1)/(sumOfAllRepeations+len(sortedCandidates)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the input sentence : سيكون كل شيء على ما يرام بعد أن\n",
      "\n",
      "Candidates \t Probability\n",
      "--------------------------------------------------\n",
      "أن يكون \t 0.007304347826086957\n",
      "أن تكون \t 0.006260869565217392\n",
      "أن هذا \t 0.00591304347826087\n",
      "أن هذه \t 0.005565217391304348\n",
      "أنه كان \t 0.0052173913043478265\n",
      "أن هناك \t 0.004869565217391304\n",
      "أن تعرف \t 0.0038260869565217392\n",
      "أن كل \t 0.0038260869565217392\n",
      "أن ترى \t 0.0034782608695652175\n",
      "أنه لم \t 0.003130434782608696\n",
      "\n",
      "the sentence after append the highest probability candidate : \tسيكون كل شيء على ما يرام بعد أن يكون\n"
     ]
    }
   ],
   "source": [
    "#OUTPUT\n",
    "print('the input sentence : '+inputxt)\n",
    "print()\n",
    "print('Candidates \\t Probability')\n",
    "print('--------------------------------------------------')\n",
    "for cand in TopN:\n",
    "    print(cand[0]+' \\t '+ cand[1])\n",
    "    \n",
    "print('\\nthe sentence after append the highest probability candidate : '+'\\t'+inputxt+' '+TopN[0][0].split()[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
